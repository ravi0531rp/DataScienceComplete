{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b23d58c4",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e78b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d81b3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\ALL_CODES_SECTIONWISE\\\\DSC_CODES\\\\Data_Science_ML_Based'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "439169d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\ALL_CODES_SECTIONWISE\\\\DSC_CODES\\\\Data_Science_ML_Based\\\\DATA\\\\Advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120283d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d665d84",
   "metadata": {},
   "source": [
    "## Train | Test Split Procedure \n",
    "\n",
    "0. Clean and adjust data as necessary for X and y\n",
    "1. Split Data in Train/Test for both X and y\n",
    "2. Fit/Train Scaler on Training X Data\n",
    "3. Scale X Test Data\n",
    "4. Create Model\n",
    "5. Fit/Train Model on X Train Data\n",
    "6. Evaluate Model on X Test Data (by creating predictions and comparing to Y_test)\n",
    "7. Adjust Parameters as Necessary and repeat steps 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7320525",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE X and y\n",
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "# TRAIN TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# SCALE DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0f88cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af11393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poor Alpha Choice on purpose!\n",
    "model = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d069f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e5c9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988cd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aab40450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.341775789034128"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888be881",
   "metadata": {},
   "source": [
    "**Adjust Parameters and Re-evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56533439",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e8571f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7682f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57eec944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3190215794287514"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a933d7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3190215794287514"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e98e0",
   "metadata": {},
   "source": [
    "## Train | Validation | Test Split Procedure \n",
    "\n",
    "This is often also called a \"hold-out\" set, since you should not adjust parameters based on the final test set, but instead use it *only* for reporting final expected performance.\n",
    "\n",
    "0. Clean and adjust data as necessary for X and y\n",
    "1. Split Data in Train/Validation/Test for both X and y\n",
    "2. Fit/Train Scaler on Training X Data\n",
    "3. Scale X Eval Data\n",
    "4. Create Model\n",
    "5. Fit/Train Model on X Train Data\n",
    "6. Evaluate Model on X Evaluation Data (by creating predictions and comparing to Y_eval)\n",
    "7. Adjust Parameters as Necessary and repeat steps 5 and 6\n",
    "8. Get final metrics on Test set (not allowed to go back and adjust after this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3be5f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3906ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 70% of data is training data, set aside other 30%\n",
    "X_train, X_OTHER, y_train, y_OTHER = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# Remaining 30% is split into evaluation and test sets\n",
    "# Each is 15% of the original data size\n",
    "X_eval, X_test, y_eval, y_test = train_test_split(X_OTHER, y_OTHER, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63fc820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_eval = scaler.transform(X_eval)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd9e5001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69db584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poor Alpha Choice on purpose!\n",
    "model = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9d71874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cffe563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = model.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83e593a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6240c018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.320101458823869"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_eval,y_eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff3a2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2abd740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "310aa477",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = model.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0dcc7cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3837830750569853"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_eval,y_eval_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15860ee5",
   "metadata": {},
   "source": [
    "**Final Evaluation (Can no longer edit parameters after this!)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ee8ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abb85f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.254260083800517"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_final_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69317c9d",
   "metadata": {},
   "source": [
    "## Cross Validation with cross_val_score\n",
    "\n",
    "----\n",
    "\n",
    "<img src=\"imgs/grid_search_cross_validation.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f2c2bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE X and y\n",
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "# TRAIN TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# SCALE DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89e55a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c8cb497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63e5878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,X_train,y_train,\n",
    "                         scoring='neg_mean_squared_error',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e29f01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.32552967,  -4.9449624 , -11.39665242,  -7.0242106 ,\n",
       "        -8.38562723])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01d40756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.215396464543607"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "190955f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a483df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,X_train,y_train,\n",
    "                         scoring='neg_mean_squared_error',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9c86392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.344839296530695"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b3b5e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e965d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "377bfa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3190215794287514"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_final_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfec83b",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "----\n",
    "\n",
    "# Cross Validation with cross_validate\n",
    "\n",
    "The cross_validate function differs from cross_val_score in two ways:\n",
    "\n",
    "It allows specifying multiple metrics for evaluation.\n",
    "\n",
    "It returns a dict containing fit-times, score-times (and optionally training scores as well as fitted estimators) in addition to the test score.\n",
    "\n",
    "For single metric evaluation, where the scoring parameter is a string, callable or None, the keys will be:\n",
    "        \n",
    "        - ['test_score', 'fit_time', 'score_time']\n",
    "\n",
    "And for multiple metric evaluation, the return value is a dict with the following keys:\n",
    "\n",
    "    ['test_<scorer1_name>', 'test_<scorer2_name>', 'test_<scorer...>', 'fit_time', 'score_time']\n",
    "\n",
    "return_train_score is set to False by default to save computation time. To evaluate the scores on the training set as well you need to be set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7ad50e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE X and y\n",
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "# TRAIN TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# SCALE DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Ridge(alpha=100)\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "scores = cross_validate(model,X_train,y_train,\n",
    "                         scoring=['neg_mean_absolute_error','neg_mean_squared_error','max_error'],cv=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43f1a256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00292087, 0.00202537, 0.00199556, 0.00299215, 0.00262403]),\n",
       " 'score_time': array([0.00218987, 0.00295973, 0.0019927 , 0.00254059, 0.00199318]),\n",
       " 'test_neg_mean_absolute_error': array([-2.31243044, -1.74653361, -2.56211701, -2.01873159, -2.27951906]),\n",
       " 'test_neg_mean_squared_error': array([ -9.32552967,  -4.9449624 , -11.39665242,  -7.0242106 ,\n",
       "         -8.38562723]),\n",
       " 'test_max_error': array([ -6.44988486,  -5.58926073, -10.33914027,  -6.61950405,\n",
       "         -7.75578515])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "548c435c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_max_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>-2.312430</td>\n",
       "      <td>-9.325530</td>\n",
       "      <td>-6.449885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>-1.746534</td>\n",
       "      <td>-4.944962</td>\n",
       "      <td>-5.589261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>-2.562117</td>\n",
       "      <td>-11.396652</td>\n",
       "      <td>-10.339140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>-2.018732</td>\n",
       "      <td>-7.024211</td>\n",
       "      <td>-6.619504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>-2.279519</td>\n",
       "      <td>-8.385627</td>\n",
       "      <td>-7.755785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_absolute_error  \\\n",
       "0  0.002921    0.002190                     -2.312430   \n",
       "1  0.002025    0.002960                     -1.746534   \n",
       "2  0.001996    0.001993                     -2.562117   \n",
       "3  0.002992    0.002541                     -2.018732   \n",
       "4  0.002624    0.001993                     -2.279519   \n",
       "\n",
       "   test_neg_mean_squared_error  test_max_error  \n",
       "0                    -9.325530       -6.449885  \n",
       "1                    -4.944962       -5.589261  \n",
       "2                   -11.396652      -10.339140  \n",
       "3                    -7.024211       -6.619504  \n",
       "4                    -8.385627       -7.755785  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d07cf6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time                        0.002512\n",
       "score_time                      0.002335\n",
       "test_neg_mean_absolute_error   -2.183866\n",
       "test_neg_mean_squared_error    -8.215396\n",
       "test_max_error                 -7.350715\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65d3e592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3190215794287514"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Ridge(alpha=1)\n",
    "scores = cross_validate(model,X_train,y_train,\n",
    "                         scoring=['neg_mean_absolute_error','neg_mean_squared_error','max_error'],cv=5)\n",
    "pd.DataFrame(scores).mean()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_final_test_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test,y_final_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49f134f",
   "metadata": {},
   "source": [
    "# GRID SEARCH\n",
    "A search consists of:\n",
    "\n",
    "* an estimator (regressor or classifier such as sklearn.svm.SVC());\n",
    "* a parameter space;\n",
    "* a method for searching or sampling candidates;\n",
    "* a cross-validation scheme \n",
    "* a score function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6a7a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "# TRAIN TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# SCALE DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a1908e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7e45c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_elastic_model = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "245151f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[0.1,1,5,10,50,100],\n",
    "              'l1_ratio':[.1, .5, .7, .9, .95, .99, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "298fe889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e39484a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
      " |  \"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
      " |  implemented in the estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object.\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (`str`) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : str, callable, list, tuple or dict, default=None\n",
      " |      Strategy to evaluate the performance of the cross-validated model on\n",
      " |      the test set.\n",
      " |  \n",
      " |      If `scoring` represents a single score, one can use:\n",
      " |  \n",
      " |      - a single string (see :ref:`scoring_parameter`);\n",
      " |      - a callable (see :ref:`scoring`) that returns a single value.\n",
      " |  \n",
      " |      If `scoring` represents multiple scores, one can use:\n",
      " |  \n",
      " |      - a list or tuple of unique strings;\n",
      " |      - a callable returning a dictionary where the keys are the metric\n",
      " |        names and the values are the metric scores;\n",
      " |      - a dictionary with metric names as keys and callables a values.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used. These splitters are instantiated\n",
      " |      with `shuffle=False` so the splits will be the same across calls.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  verbose : int\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |      - >1 : the computation time for each fold and parameter candidate is\n",
      " |        displayed;\n",
      " |      - >2 : the score is also displayed;\n",
      " |      - >3 : the fold and candidate parameter indexes are also displayed\n",
      " |        together with the starting time of the computation.\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default=n_jobs\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  GridSearchCV(estimator=SVC(),\n",
      " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split2_test_score', ...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  multimetric_ : bool\n",
      " |      Whether or not the scorers compute several metrics.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  ---------\n",
      " |  ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
      " |  train_test_split : Utility function to split the data into a development\n",
      " |      set usable for fitting a GridSearchCV instance and an evaluation set\n",
      " |      for its final evaluation.\n",
      " |  sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      " |      loss function.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      " |      \n",
      " |      **fit_params : dict of str -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Returns the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |  \n",
      " |  score_samples(self, X)\n",
      " |      Call score_samples on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``score_samples``.\n",
      " |      \n",
      " |      .. versionadded:: 0.24\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements\n",
      " |          of the underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,)\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  n_features_in_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe7f606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(estimator=base_elastic_model,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          cv=5,\n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2edd53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.1, 1, 5, 10, 50, 100],\n",
       "                         'l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cdd62d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.2s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.1, 1, 5, 10, 50, 100],\n",
       "                         'l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19eb2219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, l1_ratio=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e98b8cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'l1_ratio': 1}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d40e12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2b56731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c93fd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.387342642087474"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d12f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
