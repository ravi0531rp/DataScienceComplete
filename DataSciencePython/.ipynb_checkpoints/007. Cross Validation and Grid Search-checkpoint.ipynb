{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0686f1c",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c29b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c86010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\ALL_CODES_SECTIONWISE\\\\DSC_CODES\\\\Data_Science_ML_Based'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d239eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\ALL_CODES_SECTIONWISE\\\\DSC_CODES\\\\Data_Science_ML_Based\\\\DATA\\\\Advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b90de12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded73261",
   "metadata": {},
   "source": [
    "## Train | Test Split Procedure \n",
    "\n",
    "0. Clean and adjust data as necessary for X and y\n",
    "1. Split Data in Train/Test for both X and y\n",
    "2. Fit/Train Scaler on Training X Data\n",
    "3. Scale X Test Data\n",
    "4. Create Model\n",
    "5. Fit/Train Model on X Train Data\n",
    "6. Evaluate Model on X Test Data (by creating predictions and comparing to Y_test)\n",
    "7. Adjust Parameters as Necessary and repeat steps 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "343a1d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE X and y\n",
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "# TRAIN TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# SCALE DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a62b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99bae019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poor Alpha Choice on purpose!\n",
    "model = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "257c71d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f1285be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a0fe182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70afb39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.341775789034128"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4200b1fa",
   "metadata": {},
   "source": [
    "**Adjust Parameters and Re-evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5ab77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6b513b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf7143d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91fbd91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3190215794287514"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4110dae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3190215794287514"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae19f11",
   "metadata": {},
   "source": [
    "## Train | Validation | Test Split Procedure \n",
    "\n",
    "This is often also called a \"hold-out\" set, since you should not adjust parameters based on the final test set, but instead use it *only* for reporting final expected performance.\n",
    "\n",
    "0. Clean and adjust data as necessary for X and y\n",
    "1. Split Data in Train/Validation/Test for both X and y\n",
    "2. Fit/Train Scaler on Training X Data\n",
    "3. Scale X Eval Data\n",
    "4. Create Model\n",
    "5. Fit/Train Model on X Train Data\n",
    "6. Evaluate Model on X Evaluation Data (by creating predictions and comparing to Y_eval)\n",
    "7. Adjust Parameters as Necessary and repeat steps 5 and 6\n",
    "8. Get final metrics on Test set (not allowed to go back and adjust after this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ff0b75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "310b6d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 70% of data is training data, set aside other 30%\n",
    "X_train, X_OTHER, y_train, y_OTHER = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# Remaining 30% is split into evaluation and test sets\n",
    "# Each is 15% of the original data size\n",
    "X_eval, X_test, y_eval, y_test = train_test_split(X_OTHER, y_OTHER, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be9f1542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_eval = scaler.transform(X_eval)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6d06dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6d8207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poor Alpha Choice on purpose!\n",
    "model = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42166519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8452d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = model.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a407cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7efef161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.320101458823869"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_eval,y_eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7656e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11ae1806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3aef2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = model.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c397945e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3837830750569853"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_eval,y_eval_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088a9025",
   "metadata": {},
   "source": [
    "**Final Evaluation (Can no longer edit parameters after this!)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9dbcbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2eabbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.254260083800517"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_final_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9581b9",
   "metadata": {},
   "source": [
    "## Cross Validation with cross_val_score\n",
    "\n",
    "----\n",
    "\n",
    "<img src=\"imgs/grid_search_cross_validation.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "390396db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE X and y\n",
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "# TRAIN TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# SCALE DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "635426c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d904624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a609052",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,X_train,y_train,\n",
    "                         scoring='neg_mean_squared_error',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "870454ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.32552967,  -4.9449624 , -11.39665242,  -7.0242106 ,\n",
       "        -8.38562723])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4d49c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.215396464543607"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8db2344",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37dc2f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,X_train,y_train,\n",
    "                         scoring='neg_mean_squared_error',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b99334a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.344839296530695"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6528b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be2023d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac89f563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3190215794287514"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_final_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12511ef2",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "----\n",
    "\n",
    "# Cross Validation with cross_validate\n",
    "\n",
    "The cross_validate function differs from cross_val_score in two ways:\n",
    "\n",
    "It allows specifying multiple metrics for evaluation.\n",
    "\n",
    "It returns a dict containing fit-times, score-times (and optionally training scores as well as fitted estimators) in addition to the test score.\n",
    "\n",
    "For single metric evaluation, where the scoring parameter is a string, callable or None, the keys will be:\n",
    "        \n",
    "        - ['test_score', 'fit_time', 'score_time']\n",
    "\n",
    "And for multiple metric evaluation, the return value is a dict with the following keys:\n",
    "\n",
    "    ['test_<scorer1_name>', 'test_<scorer2_name>', 'test_<scorer...>', 'fit_time', 'score_time']\n",
    "\n",
    "return_train_score is set to False by default to save computation time. To evaluate the scores on the training set as well you need to be set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae0fac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE X and y\n",
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "# TRAIN TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# SCALE DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Ridge(alpha=100)\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "scores = cross_validate(model,X_train,y_train,\n",
    "                         scoring=['neg_mean_absolute_error','neg_mean_squared_error','max_error'],cv=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45fb85b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00292087, 0.00202537, 0.00199556, 0.00299215, 0.00262403]),\n",
       " 'score_time': array([0.00218987, 0.00295973, 0.0019927 , 0.00254059, 0.00199318]),\n",
       " 'test_neg_mean_absolute_error': array([-2.31243044, -1.74653361, -2.56211701, -2.01873159, -2.27951906]),\n",
       " 'test_neg_mean_squared_error': array([ -9.32552967,  -4.9449624 , -11.39665242,  -7.0242106 ,\n",
       "         -8.38562723]),\n",
       " 'test_max_error': array([ -6.44988486,  -5.58926073, -10.33914027,  -6.61950405,\n",
       "         -7.75578515])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42078296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_max_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>-2.312430</td>\n",
       "      <td>-9.325530</td>\n",
       "      <td>-6.449885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>-1.746534</td>\n",
       "      <td>-4.944962</td>\n",
       "      <td>-5.589261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>-2.562117</td>\n",
       "      <td>-11.396652</td>\n",
       "      <td>-10.339140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>-2.018732</td>\n",
       "      <td>-7.024211</td>\n",
       "      <td>-6.619504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>-2.279519</td>\n",
       "      <td>-8.385627</td>\n",
       "      <td>-7.755785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_absolute_error  \\\n",
       "0  0.002921    0.002190                     -2.312430   \n",
       "1  0.002025    0.002960                     -1.746534   \n",
       "2  0.001996    0.001993                     -2.562117   \n",
       "3  0.002992    0.002541                     -2.018732   \n",
       "4  0.002624    0.001993                     -2.279519   \n",
       "\n",
       "   test_neg_mean_squared_error  test_max_error  \n",
       "0                    -9.325530       -6.449885  \n",
       "1                    -4.944962       -5.589261  \n",
       "2                   -11.396652      -10.339140  \n",
       "3                    -7.024211       -6.619504  \n",
       "4                    -8.385627       -7.755785  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3340e55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time                        0.002512\n",
       "score_time                      0.002335\n",
       "test_neg_mean_absolute_error   -2.183866\n",
       "test_neg_mean_squared_error    -8.215396\n",
       "test_max_error                 -7.350715\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba0adcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3190215794287514"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Ridge(alpha=1)\n",
    "scores = cross_validate(model,X_train,y_train,\n",
    "                         scoring=['neg_mean_absolute_error','neg_mean_squared_error','max_error'],cv=5)\n",
    "pd.DataFrame(scores).mean()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_final_test_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test,y_final_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c60886",
   "metadata": {},
   "source": [
    "# GRID SEARCH\n",
    "A search consists of:\n",
    "\n",
    "* an estimator (regressor or classifier such as sklearn.svm.SVC());\n",
    "* a parameter space;\n",
    "* a method for searching or sampling candidates;\n",
    "* a cross-validation scheme \n",
    "* a score function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d24c3b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "# TRAIN TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# SCALE DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c11df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb0c58e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_elastic_model = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ee19ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[0.1,1,5,10,50,100],\n",
    "              'l1_ratio':[.1, .5, .7, .9, .95, .99, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53053cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce06f593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
      " |  \"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
      " |  implemented in the estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object.\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (`str`) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : str, callable, list, tuple or dict, default=None\n",
      " |      Strategy to evaluate the performance of the cross-validated model on\n",
      " |      the test set.\n",
      " |  \n",
      " |      If `scoring` represents a single score, one can use:\n",
      " |  \n",
      " |      - a single string (see :ref:`scoring_parameter`);\n",
      " |      - a callable (see :ref:`scoring`) that returns a single value.\n",
      " |  \n",
      " |      If `scoring` represents multiple scores, one can use:\n",
      " |  \n",
      " |      - a list or tuple of unique strings;\n",
      " |      - a callable returning a dictionary where the keys are the metric\n",
      " |        names and the values are the metric scores;\n",
      " |      - a dictionary with metric names as keys and callables a values.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used. These splitters are instantiated\n",
      " |      with `shuffle=False` so the splits will be the same across calls.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  verbose : int\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |      - >1 : the computation time for each fold and parameter candidate is\n",
      " |        displayed;\n",
      " |      - >2 : the score is also displayed;\n",
      " |      - >3 : the fold and candidate parameter indexes are also displayed\n",
      " |        together with the starting time of the computation.\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default=n_jobs\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  GridSearchCV(estimator=SVC(),\n",
      " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split2_test_score', ...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  multimetric_ : bool\n",
      " |      Whether or not the scorers compute several metrics.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  ---------\n",
      " |  ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
      " |  train_test_split : Utility function to split the data into a development\n",
      " |      set usable for fitting a GridSearchCV instance and an evaluation set\n",
      " |      for its final evaluation.\n",
      " |  sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      " |      loss function.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      " |      \n",
      " |      **fit_params : dict of str -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Returns the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |  \n",
      " |  score_samples(self, X)\n",
      " |      Call score_samples on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``score_samples``.\n",
      " |      \n",
      " |      .. versionadded:: 0.24\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements\n",
      " |          of the underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,)\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  n_features_in_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a859f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(estimator=base_elastic_model,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          cv=5,\n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ecda0ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.1, 1, 5, 10, 50, 100],\n",
       "                         'l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c5c066b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.2s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.1, 1, 5, 10, 50, 100],\n",
       "                         'l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "762941d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, l1_ratio=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4fb48583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'l1_ratio': 1}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe689616",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14730193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ad6cadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.387342642087474"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22084c4a",
   "metadata": {},
   "source": [
    "----------------------\n",
    "----------------------\n",
    "\n",
    "#         ML PROJECT BASED ON THE AMES HOUSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c83f418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\ALL_CODES_SECTIONWISE\\\\DSC_CODES\\\\Data_Science_ML_Based\\\\DATA\\\\AMES_Final_DF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4417b050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>...</th>\n",
       "      <th>Sale Type_ConLw</th>\n",
       "      <th>Sale Type_New</th>\n",
       "      <th>Sale Type_Oth</th>\n",
       "      <th>Sale Type_VWD</th>\n",
       "      <th>Sale Type_WD</th>\n",
       "      <th>Sale Condition_AdjLand</th>\n",
       "      <th>Sale Condition_Alloca</th>\n",
       "      <th>Sale Condition_Family</th>\n",
       "      <th>Sale Condition_Normal</th>\n",
       "      <th>Sale Condition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1960</td>\n",
       "      <td>1960</td>\n",
       "      <td>112.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1968</td>\n",
       "      <td>1968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  274 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lot Frontage  Lot Area  Overall Qual  Overall Cond  Year Built  \\\n",
       "0         141.0     31770             6             5        1960   \n",
       "1          80.0     11622             5             6        1961   \n",
       "2          81.0     14267             6             6        1958   \n",
       "3          93.0     11160             7             5        1968   \n",
       "4          74.0     13830             5             5        1997   \n",
       "\n",
       "   Year Remod/Add  Mas Vnr Area  BsmtFin SF 1  BsmtFin SF 2  Bsmt Unf SF  ...  \\\n",
       "0            1960         112.0         639.0           0.0        441.0  ...   \n",
       "1            1961           0.0         468.0         144.0        270.0  ...   \n",
       "2            1958         108.0         923.0           0.0        406.0  ...   \n",
       "3            1968           0.0        1065.0           0.0       1045.0  ...   \n",
       "4            1998           0.0         791.0           0.0        137.0  ...   \n",
       "\n",
       "   Sale Type_ConLw  Sale Type_New  Sale Type_Oth  Sale Type_VWD  \\\n",
       "0                0              0              0              0   \n",
       "1                0              0              0              0   \n",
       "2                0              0              0              0   \n",
       "3                0              0              0              0   \n",
       "4                0              0              0              0   \n",
       "\n",
       "   Sale Type_WD   Sale Condition_AdjLand  Sale Condition_Alloca  \\\n",
       "0              1                       0                      0   \n",
       "1              1                       0                      0   \n",
       "2              1                       0                      0   \n",
       "3              1                       0                      0   \n",
       "4              1                       0                      0   \n",
       "\n",
       "   Sale Condition_Family  Sale Condition_Normal  Sale Condition_Partial  \n",
       "0                      0                      1                       0  \n",
       "1                      0                      1                       0  \n",
       "2                      0                      1                       0  \n",
       "3                      0                      1                       0  \n",
       "4                      0                      1                       0  \n",
       "\n",
       "[5 rows x 274 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "49c78409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    274\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().value_counts() # all 274 cols don't have any na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1a4c70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['SalePrice'], axis=1)\n",
    "y = df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5842588d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>...</th>\n",
       "      <th>Sale Type_ConLw</th>\n",
       "      <th>Sale Type_New</th>\n",
       "      <th>Sale Type_Oth</th>\n",
       "      <th>Sale Type_VWD</th>\n",
       "      <th>Sale Type_WD</th>\n",
       "      <th>Sale Condition_AdjLand</th>\n",
       "      <th>Sale Condition_Alloca</th>\n",
       "      <th>Sale Condition_Family</th>\n",
       "      <th>Sale Condition_Normal</th>\n",
       "      <th>Sale Condition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141.000000</td>\n",
       "      <td>31770</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1960</td>\n",
       "      <td>1960</td>\n",
       "      <td>112.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>11160</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1968</td>\n",
       "      <td>1968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>7937</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>75.144444</td>\n",
       "      <td>8885</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1983</td>\n",
       "      <td>1983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>10441</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>10010</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1974</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>9627</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>94.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2925 rows  273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lot Frontage  Lot Area  Overall Qual  Overall Cond  Year Built  \\\n",
       "0       141.000000     31770             6             5        1960   \n",
       "1        80.000000     11622             5             6        1961   \n",
       "2        81.000000     14267             6             6        1958   \n",
       "3        93.000000     11160             7             5        1968   \n",
       "4        74.000000     13830             5             5        1997   \n",
       "...            ...       ...           ...           ...         ...   \n",
       "2920     37.000000      7937             6             6        1984   \n",
       "2921     75.144444      8885             5             5        1983   \n",
       "2922     62.000000     10441             5             5        1992   \n",
       "2923     77.000000     10010             5             5        1974   \n",
       "2924     74.000000      9627             7             5        1993   \n",
       "\n",
       "      Year Remod/Add  Mas Vnr Area  BsmtFin SF 1  BsmtFin SF 2  Bsmt Unf SF  \\\n",
       "0               1960         112.0         639.0           0.0        441.0   \n",
       "1               1961           0.0         468.0         144.0        270.0   \n",
       "2               1958         108.0         923.0           0.0        406.0   \n",
       "3               1968           0.0        1065.0           0.0       1045.0   \n",
       "4               1998           0.0         791.0           0.0        137.0   \n",
       "...              ...           ...           ...           ...          ...   \n",
       "2920            1984           0.0         819.0           0.0        184.0   \n",
       "2921            1983           0.0         301.0         324.0        239.0   \n",
       "2922            1992           0.0         337.0           0.0        575.0   \n",
       "2923            1975           0.0        1071.0         123.0        195.0   \n",
       "2924            1994          94.0         758.0           0.0        238.0   \n",
       "\n",
       "      ...  Sale Type_ConLw  Sale Type_New  Sale Type_Oth  Sale Type_VWD  \\\n",
       "0     ...                0              0              0              0   \n",
       "1     ...                0              0              0              0   \n",
       "2     ...                0              0              0              0   \n",
       "3     ...                0              0              0              0   \n",
       "4     ...                0              0              0              0   \n",
       "...   ...              ...            ...            ...            ...   \n",
       "2920  ...                0              0              0              0   \n",
       "2921  ...                0              0              0              0   \n",
       "2922  ...                0              0              0              0   \n",
       "2923  ...                0              0              0              0   \n",
       "2924  ...                0              0              0              0   \n",
       "\n",
       "      Sale Type_WD   Sale Condition_AdjLand  Sale Condition_Alloca  \\\n",
       "0                 1                       0                      0   \n",
       "1                 1                       0                      0   \n",
       "2                 1                       0                      0   \n",
       "3                 1                       0                      0   \n",
       "4                 1                       0                      0   \n",
       "...             ...                     ...                    ...   \n",
       "2920              1                       0                      0   \n",
       "2921              1                       0                      0   \n",
       "2922              1                       0                      0   \n",
       "2923              1                       0                      0   \n",
       "2924              1                       0                      0   \n",
       "\n",
       "      Sale Condition_Family  Sale Condition_Normal  Sale Condition_Partial  \n",
       "0                         0                      1                       0  \n",
       "1                         0                      1                       0  \n",
       "2                         0                      1                       0  \n",
       "3                         0                      1                       0  \n",
       "4                         0                      1                       0  \n",
       "...                     ...                    ...                     ...  \n",
       "2920                      0                      1                       0  \n",
       "2921                      0                      1                       0  \n",
       "2922                      0                      1                       0  \n",
       "2923                      0                      1                       0  \n",
       "2924                      0                      1                       0  \n",
       "\n",
       "[2925 rows x 273 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf4480d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       215000\n",
       "1       105000\n",
       "2       172000\n",
       "3       244000\n",
       "4       189900\n",
       "         ...  \n",
       "2920    142500\n",
       "2921    131000\n",
       "2922    132000\n",
       "2923    170000\n",
       "2924    188000\n",
       "Name: SalePrice, Length: 2925, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "be5381e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ad5a02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the shuffling applied to the data before applying the split.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like, default=None\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "        Read more in the :ref:`User Guide <stratification>`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "51bfb5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ecc58bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "160c033f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24211099, -0.51696976, -0.7631448 , ..., -0.13038998,\n",
       "         0.46443986, -0.30126134],\n",
       "       [ 0.79071912,  0.43175591,  2.06387436, ..., -0.13038998,\n",
       "         0.46443986, -0.30126134],\n",
       "       [ 0.5511309 ,  0.04829094, -0.7631448 , ..., -0.13038998,\n",
       "        -2.15313128,  3.31937718],\n",
       "       ...,\n",
       "       [ 1.46156615,  0.74066194,  0.65036478, ..., -0.13038998,\n",
       "         0.46443986, -0.30126134],\n",
       "       [ 0.93447206,  0.42215261,  2.06387436, ..., -0.13038998,\n",
       "         0.46443986, -0.30126134],\n",
       "       [ 0.02403681, -0.17338515,  0.65036478, ..., -0.13038998,\n",
       "         0.46443986, -0.30126134]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "sc.transform(X_train)\n",
    "sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d9c935da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "73270514",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_elastic = ElasticNet() # max_iter=100000 to avoid warnings of no convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "83ff3923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ElasticNet in module sklearn.linear_model._coordinate_descent:\n",
      "\n",
      "class ElasticNet(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      " |  ElasticNet(alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, normalize=False, precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      " |  \n",
      " |  Linear regression with combined L1 and L2 priors as regularizer.\n",
      " |  \n",
      " |  Minimizes the objective function::\n",
      " |  \n",
      " |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      " |          + alpha * l1_ratio * ||w||_1\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      " |  \n",
      " |  If you are interested in controlling the L1 and L2 penalty\n",
      " |  separately, keep in mind that this is equivalent to::\n",
      " |  \n",
      " |          a * ||w||_1 + 0.5 * b * ||w||_2^2\n",
      " |  \n",
      " |  where::\n",
      " |  \n",
      " |          alpha = a + b and l1_ratio = a / (a + b)\n",
      " |  \n",
      " |  The parameter l1_ratio corresponds to alpha in the glmnet R package while\n",
      " |  alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio\n",
      " |  = 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable,\n",
      " |  unless you supply your own sequence of alpha.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <elastic_net>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  alpha : float, default=1.0\n",
      " |      Constant that multiplies the penalty terms. Defaults to 1.0.\n",
      " |      See the notes for the exact mathematical meaning of this\n",
      " |      parameter. ``alpha = 0`` is equivalent to an ordinary least square,\n",
      " |      solved by the :class:`LinearRegression` object. For numerical\n",
      " |      reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
      " |      Given this, you should use the :class:`LinearRegression` object.\n",
      " |  \n",
      " |  l1_ratio : float, default=0.5\n",
      " |      The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n",
      " |      ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n",
      " |      is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n",
      " |      combination of L1 and L2.\n",
      " |  \n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether the intercept should be estimated or not. If ``False``, the\n",
      " |      data is assumed to be already centered.\n",
      " |  \n",
      " |  normalize : bool, default=False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`~sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      " |      on an estimator with ``normalize=False``.\n",
      " |  \n",
      " |  precompute : bool or array-like of shape (n_features, n_features),                 default=False\n",
      " |      Whether to use a precomputed Gram matrix to speed up\n",
      " |      calculations. The Gram matrix can also be passed as argument.\n",
      " |      For sparse input this option is always ``False`` to preserve sparsity.\n",
      " |  \n",
      " |  max_iter : int, default=1000\n",
      " |      The maximum number of iterations.\n",
      " |  \n",
      " |  copy_X : bool, default=True\n",
      " |      If ``True``, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      The tolerance for the optimization: if the updates are\n",
      " |      smaller than ``tol``, the optimization code checks the\n",
      " |      dual gap for optimality and continues until it is smaller\n",
      " |      than ``tol``.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  positive : bool, default=False\n",
      " |      When set to ``True``, forces the coefficients to be positive.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      The seed of the pseudo random number generator that selects a random\n",
      " |      feature to update. Used when ``selection`` == 'random'.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  selection : {'cyclic', 'random'}, default='cyclic'\n",
      " |      If set to 'random', a random coefficient is updated every iteration\n",
      " |      rather than looping over features sequentially by default. This\n",
      " |      (setting to 'random') often leads to significantly faster convergence\n",
      " |      especially when tol is higher than 1e-4.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      " |      Parameter vector (w in the cost function formula).\n",
      " |  \n",
      " |  sparse_coef_ : sparse matrix of shape (n_features,) or             (n_tasks, n_features)\n",
      " |      Sparse representation of the `coef_`.\n",
      " |  \n",
      " |  intercept_ : float or ndarray of shape (n_targets,)\n",
      " |      Independent term in decision function.\n",
      " |  \n",
      " |  n_iter_ : list of int\n",
      " |      Number of iterations run by the coordinate descent solver to reach\n",
      " |      the specified tolerance.\n",
      " |  \n",
      " |  dual_gap_ : float or ndarray of shape (n_targets,)\n",
      " |      Given param alpha, the dual gaps at the end of the optimization,\n",
      " |      same shape as each observation of y.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.linear_model import ElasticNet\n",
      " |  >>> from sklearn.datasets import make_regression\n",
      " |  \n",
      " |  >>> X, y = make_regression(n_features=2, random_state=0)\n",
      " |  >>> regr = ElasticNet(random_state=0)\n",
      " |  >>> regr.fit(X, y)\n",
      " |  ElasticNet(random_state=0)\n",
      " |  >>> print(regr.coef_)\n",
      " |  [18.83816048 64.55968825]\n",
      " |  >>> print(regr.intercept_)\n",
      " |  1.451...\n",
      " |  >>> print(regr.predict([[0, 0]]))\n",
      " |  [1.451...]\n",
      " |  \n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  To avoid unnecessary memory duplication the X argument of the fit method\n",
      " |  should be directly passed as a Fortran-contiguous numpy array.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  ElasticNetCV : Elastic net model with best model selection by\n",
      " |      cross-validation.\n",
      " |  SGDRegressor : Implements elastic net regression with incremental training.\n",
      " |  SGDClassifier : Implements logistic regression with elastic net penalty\n",
      " |      (``SGDClassifier(loss=\"log\", penalty=\"elasticnet\")``).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ElasticNet\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      sklearn.linear_model._base.LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, normalize=False, precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, check_input=True)\n",
      " |      Fit model with coordinate descent.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {ndarray, sparse matrix} of (n_samples, n_features)\n",
      " |          Data.\n",
      " |      \n",
      " |      y : {ndarray, sparse matrix} of shape (n_samples,) or             (n_samples, n_targets)\n",
      " |          Target. Will be cast to X's dtype if necessary.\n",
      " |      \n",
      " |      sample_weight : float or array-like of shape (n_samples,), default=None\n",
      " |          Sample weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.23\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      Coordinate descent is an algorithm that considers each column of\n",
      " |      data at a time hence it will automatically convert the X input\n",
      " |      as a Fortran-contiguous numpy array if necessary.\n",
      " |      \n",
      " |      To avoid memory re-allocation it is advised to allocate the\n",
      " |      initial data in memory directly using that format.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  path = enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
      " |      Compute elastic net path with coordinate descent.\n",
      " |      \n",
      " |      The elastic net optimization function varies for mono and multi-outputs.\n",
      " |      \n",
      " |      For mono-output tasks it is::\n",
      " |      \n",
      " |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      " |          + alpha * l1_ratio * ||w||_1\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      " |      \n",
      " |      For multi-output tasks it is::\n",
      " |      \n",
      " |          (1 / (2 * n_samples)) * ||Y - XW||_Fro^2\n",
      " |          + alpha * l1_ratio * ||W||_21\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      " |      \n",
      " |      Where::\n",
      " |      \n",
      " |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      " |      \n",
      " |      i.e. the sum of norm of each row.\n",
      " |      \n",
      " |      Read more in the :ref:`User Guide <elastic_net>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      " |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      " |          can be sparse.\n",
      " |      \n",
      " |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_outputs)\n",
      " |          Target values.\n",
      " |      \n",
      " |      l1_ratio : float, default=0.5\n",
      " |          Number between 0 and 1 passed to elastic net (scaling between\n",
      " |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso.\n",
      " |      \n",
      " |      eps : float, default=1e-3\n",
      " |          Length of the path. ``eps=1e-3`` means that\n",
      " |          ``alpha_min / alpha_max = 1e-3``.\n",
      " |      \n",
      " |      n_alphas : int, default=100\n",
      " |          Number of alphas along the regularization path.\n",
      " |      \n",
      " |      alphas : ndarray, default=None\n",
      " |          List of alphas where to compute the models.\n",
      " |          If None alphas are set automatically.\n",
      " |      \n",
      " |      precompute : 'auto', bool or array-like of shape (n_features, n_features),                 default='auto'\n",
      " |          Whether to use a precomputed Gram matrix to speed up\n",
      " |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      " |          matrix can also be passed as argument.\n",
      " |      \n",
      " |      Xy : array-like of shape (n_features,) or (n_features, n_outputs),         default=None\n",
      " |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      " |          only when the Gram matrix is precomputed.\n",
      " |      \n",
      " |      copy_X : bool, default=True\n",
      " |          If ``True``, X will be copied; else, it may be overwritten.\n",
      " |      \n",
      " |      coef_init : ndarray of shape (n_features, ), default=None\n",
      " |          The initial values of the coefficients.\n",
      " |      \n",
      " |      verbose : bool or int, default=False\n",
      " |          Amount of verbosity.\n",
      " |      \n",
      " |      return_n_iter : bool, default=False\n",
      " |          Whether to return the number of iterations or not.\n",
      " |      \n",
      " |      positive : bool, default=False\n",
      " |          If set to True, forces coefficients to be positive.\n",
      " |          (Only allowed when ``y.ndim == 1``).\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          If set to False, the input validation checks are skipped (including the\n",
      " |          Gram matrix when provided). It is assumed that they are handled\n",
      " |          by the caller.\n",
      " |      \n",
      " |      **params : kwargs\n",
      " |          Keyword arguments passed to the coordinate descent solver.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      alphas : ndarray of shape (n_alphas,)\n",
      " |          The alphas along the path where models are computed.\n",
      " |      \n",
      " |      coefs : ndarray of shape (n_features, n_alphas) or             (n_outputs, n_features, n_alphas)\n",
      " |          Coefficients along the path.\n",
      " |      \n",
      " |      dual_gaps : ndarray of shape (n_alphas,)\n",
      " |          The dual gaps at the end of the optimization for each alpha.\n",
      " |      \n",
      " |      n_iters : list of int\n",
      " |          The number of iterations taken by the coordinate descent optimizer to\n",
      " |          reach the specified tolerance for each alpha.\n",
      " |          (Is returned when ``return_n_iter`` is set to True).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      MultiTaskElasticNet\n",
      " |      MultiTaskElasticNetCV\n",
      " |      ElasticNet\n",
      " |      ElasticNetCV\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For an example, see\n",
      " |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      " |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  sparse_coef_\n",
      " |      Sparse representation of the fitted `coef_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination :math:`R^2` of the\n",
      " |      prediction.\n",
      " |      \n",
      " |      The coefficient :math:`R^2` is defined as :math:`(1 - \\frac{u}{v})`,\n",
      " |      where :math:`u` is the residual sum of squares ``((y_true - y_pred)\n",
      " |      ** 2).sum()`` and :math:`v` is the total sum of squares ``((y_true -\n",
      " |      y_true.mean()) ** 2).sum()``. The best possible score is 1.0 and it\n",
      " |      can be negative (because the model can be arbitrarily worse). A\n",
      " |      constant model that always predicts the expected value of `y`,\n",
      " |      disregarding the input features, would get a :math:`R^2` score of\n",
      " |      0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ElasticNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "20969aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {\n",
    "    \n",
    "    \"alpha\":[1,  10, 100],\n",
    "    \"l1_ratio\":[0.1,0.3,0.5,0.7,0.9]\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2d16f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b74e89c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(estimator=model_elastic,\n",
    "                          param_grid=grid_param,\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          cv=None,\n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9198296c",
   "metadata": {},
   "source": [
    "[Model doesn't converge StackOverflow](https://stackoverflow.com/questions/20681864/lasso-on-sklearn-does-not-converge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ab05baeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 889062797695.3286, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 916772943485.225, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1011875109266.3461, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 985961982434.3499, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 942223182239.2853, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 849857071156.2238, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 875182402358.4644, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 967502228539.0779, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 943208762920.4945, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 897925825580.3909, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.3; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 794302727902.9866, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 815254867378.043, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 904024752033.7104, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 882137334247.1655, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 833876660660.104, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 704384138841.1249, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 715413711926.1855, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 799747242830.1844, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 781772744004.2485, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 725488976522.2793, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 482560261569.10345, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 453900439413.41266, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 536550544529.42413, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 525380359473.382, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 447015602201.2683, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1080229523374.9949, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1106376224115.3977, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1219332210176.7869, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1188087582963.9429, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1134493849316.966, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1058563807596.067, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1082620914287.6443, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1194219237671.1133, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1163568816673.0933, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1106793601466.047, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.3; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1022968995217.0188, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1043380369991.9851, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1152924164526.9292, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1123286725797.9375, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1061027169164.5116, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 949996052837.896, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 961950971096.6022, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1068060708877.3441, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1040656930667.2584, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 966401701538.47, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 686859580227.5824, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 657857783231.9202, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 759508304657.4076, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 740741391655.9678, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 626979081112.8772, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1143848686252.2136, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1168652179345.7825, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1287389362034.365, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1255104556002.1895, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1197415646187.6619, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1109872204761.0352, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1128746669409.7488, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1246323429955.5698, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1215298581222.699, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1151084967419.234, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.3; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1071255043570.6289, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1082230568379.0015, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1198289347064.888, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1170950066601.329, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1097834521953.8813, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1009985607921.5831, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1013953986910.3372, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1126359918695.2146, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1098740328305.5764, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1012336522343.6738, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 789230443458.6521, tolerance: 1355206692.5276787\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 756006046540.021, tolerance: 1307913805.6588457\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 858541755038.0745, tolerance: 1415056940.0061066\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 837123490690.5942, tolerance: 1438198040.088288\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 714155426054.9204, tolerance: 1345680018.2551236\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 618699443789.2075, tolerance: 1715818191.2283125\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [1, 10, 100],\n",
       "                         'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "14d25644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1, 'l1_ratio': 0.9}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6f62eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9e3cf827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2d654449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16188.774701743447"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f95902db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180815.53743589742"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SalePrice'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d56aa5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.953198896130637"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*mean_absolute_error(y_pred, y_test)/df['SalePrice'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e4299d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
